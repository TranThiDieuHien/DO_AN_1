{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phân_tích_dữ_liệu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhj8i8MuQxe0iylW+OVySy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranThiDieuHien/DO_AN_1/blob/main/Ph%C3%A2n_t%C3%ADch_d%E1%BB%AF_li%E1%BB%87u.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39MqihO1txVd"
      },
      "outputs": [],
      "source": [
        "#import thư viện\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [16, 9]\n",
        "plt.rcParams['figure.dpi'] = 50\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "import os\n",
        "import string\n",
        "from scipy.stats import norm\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "stopwords = list(STOPWORDS)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score \n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer as CVTZ\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "\n",
        "def RMSE(Y,YHAT):\n",
        "    return np.sqrt(mean_squared_error(Y,YHAT))"
      ],
      "metadata": {
        "id": "VpFHrZRsA3yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOTEL INFORMATION"
      ],
      "metadata": {
        "id": "6L7OK_CTwtfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doc file\n",
        "data = pd.read_csv(\"ThuaThienHue_Infor.csv\")"
      ],
      "metadata": {
        "id": "WRv-aO45t5M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(10)"
      ],
      "metadata": {
        "id": "nTnK2HpNxCn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns.values"
      ],
      "metadata": {
        "id": "SH9z-QIo0WsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tính phần trăm cho từng giá trị trong cột dữ liệu và vẽ biểu đồ trực quan barplot\n",
        "def stat_table(a, size = (10,15)):\n",
        "    x = data.groupby(a)[a].count()\n",
        "    dt = pd.DataFrame(x)\n",
        "    dt.columns = ['Percent']\n",
        "    percent = []\n",
        "    for i in dt['Percent']:\n",
        "        x = (i/len(data[a]))*100\n",
        "        percent.append(x)\n",
        "    dt['Percent'] = percent\n",
        "    print(dt)\n",
        "    mylabels = dt.index\n",
        "    fig = plt.figure(figsize = (5, 10))\n",
        "    # barplot\n",
        "    sns.barplot(percent, mylabels, data = dt, orient = 'h')"
      ],
      "metadata": {
        "id": "1zeN05quxhkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stat_table(\"HReview\")"
      ],
      "metadata": {
        "id": "-1Vf1L9c0KjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta thấy được rằng số lượng khách sạn được đánh giá là Excellent và Very good là rất cao, chiếm số phần trăm lớn hơn gấp nhiều lần so với Average, Poor và Terrible.\n",
        "\n",
        "=> Chứng tỏ độ thỏa mãn của khách hàng đối với đa số khách sạn ở Huế là rất cao\n",
        "\n",
        "=> Khách sạn ở Huế phù hợp để được chọn là nơi nghỉ ngơi khi đi du lịch, công tác tại Huế.\n"
      ],
      "metadata": {
        "id": "YNicXBXx0sHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = data.dropna()\n",
        "print(new_data)"
      ],
      "metadata": {
        "id": "SJOlTvKy2wEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sap xep lai du lieu theo thu tu\n",
        "index = []\n",
        "print(len(new_data))\n",
        "for i in range (1, len(new_data)+1):\n",
        "    index.append(i)\n",
        "new_data[\"Index\"] = index\n",
        "index1 = new_data.set_index(\"Index\")\n",
        "new_data = index1.sort_index()\n",
        "new_data.head(10)"
      ],
      "metadata": {
        "id": "kgXCxrhB3Uwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = []\n",
        "atc = new_data[\"HAttractions\"]\n",
        "gfw = new_data[\"HGFW\"]\n",
        "rn = new_data[\"HRestaurants\"]\n",
        "for i in range(1, len(new_data)+1):\n",
        "    loca = atc[i] + gfw[i] + rn[i]\n",
        "    location.append(loca)\n",
        "new_data[\"Location\"] = location\n",
        "print(new_data[[\"HName\", \"Location\"]].sample(10))"
      ],
      "metadata": {
        "id": "jyoUXh-X1Rlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Xoa ky tu \"&\" trong cot\n",
        "new_data[\"HPMax\"] = new_data[\"HPMax\"].str.replace(r'\\D', '')"
      ],
      "metadata": {
        "id": "pPWIvEE35eUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phát biểu giả thuyết\n",
        "- $$H_{0}: \\mu_{0} = \\mu_{1}$$\n",
        "    Giá tiền tỉ lệ thuận với số lượng địa điểm vui chơi, ăn uống\n",
        "- $$H_{1}: \\mu_{0} <> \\mu_{1}$$\n",
        "    Giá tiền không tỉ lệ thuận với số lượng địa điểm vui chơi, ăn uống"
      ],
      "metadata": {
        "id": "5IJi_xjS4byD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Su dung thong ke t_test\n",
        "for i in range(1, len(new_data)+1):\n",
        "      new_data[\"HPMax\"][i] = int(new_data[\"HPMax\"][i])\n",
        "      new_data[\"Location\"][i] = int(new_data[\"Location\"][i] )\n",
        "stat, p_value = stats.ttest_ind(new_data[\"HPMax\"], new_data[\"Location\"])\n",
        "print('Stat =', stat, 'P_value =', p_value)\n",
        "if p_value < 0.05:\n",
        "    print('''Có bằng chứng thống kê để bác bỏ giả thuyết H0. Điều này ngụ ý rằng\n",
        "          giá tiền khách sạn không tỉ lệ thuận với số lượng địa điểm vui chơi, ăn uống gần khách sạn''')\n",
        "else:\n",
        "    print('''Chưa có bằng chứng thống kê để bác bỏ giả thuyết H0. Điều này ngụ ý rằng\n",
        "          giá tiền khách sạn tỉ lệ thuận với số lượng địa điểm vui chơi, ăn uống gần khách sạn''')"
      ],
      "metadata": {
        "id": "EJf9g7G34bIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét: Giá tiền khách sạn không tỉ lệ thuận với số lượng địa điểm vui chơi, ăn uống gần khách sạn."
      ],
      "metadata": {
        "id": "3iPJNYeF_cP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOTEL REVIEW COMMENTS"
      ],
      "metadata": {
        "id": "o-ZypTxXw_6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doc file\n",
        "data_comment = pd.read_csv(\"ThuaThienHue.csv\")"
      ],
      "metadata": {
        "id": "mGfja-5oxNwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment.sample(4)"
      ],
      "metadata": {
        "id": "ZEvdBYwHxPx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kiểm tra các giá trị null"
      ],
      "metadata": {
        "id": "z7px-Yq3BDcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiem tra cac gia tri null\n",
        "data_comment.isnull().sum()"
      ],
      "metadata": {
        "id": "IEaLlzi1xi0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Làm sạch dữ liệu"
      ],
      "metadata": {
        "id": "Pw2uUWy0Buoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def  clean_text(text):\n",
        "    \"\"\"\n",
        "    Lam sach cac du lieu van ban\n",
        "    * ky hieu\n",
        "    * doi thanh lower case\n",
        "    \"\"\"\n",
        "    text = text.str.lower()\n",
        "    text = text.apply(lambda T: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", str(T))  )\n",
        "        \n",
        "    return text"
      ],
      "metadata": {
        "id": "J1n6oztGBVZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment.columns.values"
      ],
      "metadata": {
        "id": "XwxXcZS8B9Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment['HComment']= clean_text(data_comment['HComment'])"
      ],
      "metadata": {
        "id": "9yxsVsVUBqxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment[[\"HComment\", 'HTravelerRating']].sample(10)"
      ],
      "metadata": {
        "id": "aGckfpn7CjAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đếm số lượng từng Rating"
      ],
      "metadata": {
        "id": "ZhEKQ5eJC8iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment.HTravelerRating.value_counts()"
      ],
      "metadata": {
        "id": "VWZAm2fnC8BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=data_comment,x='HTravelerRating', palette=\"Set3\")"
      ],
      "metadata": {
        "id": "DjVeNYl_DTBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nhận xét: Số lượng rating 5 sao cho các khách sạn ở Huế cao gấp nhiều lần tổng rating 1 đến 4 sao.\n",
        "\n",
        "=> Điều này có nghĩa rằng các khách sạn ở Huế rất tốt và phù hợp với nhu cầu của khách hàng. \n",
        "\n"
      ],
      "metadata": {
        "id": "Xo6WKadxD5s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta có thể thấy rõ rằng biến mục tiêu (Rating) không cân bằng, vì có sự khác biệt rất lớn trong rating từ 1 và 5. Vì vậy, ở đây ta sẽ sử dụng một số kỹ thuật lấy mẫu để cân bằng các lớp này."
      ],
      "metadata": {
        "id": "9qLcq5RHEZEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lấy số lượng từ trong mỗi bài đánh giá"
      ],
      "metadata": {
        "id": "VXodvQnUEfJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Lấy số lượng từ bằng cách tách chúng theo dấu cách\n",
        "words_per_review = [len(x.split(\" \")) for x in data_comment['HComment']]\n",
        "sns.distplot(words_per_review,fit=norm, kde=False)"
      ],
      "metadata": {
        "id": "g5Xy8j9rEg8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Wordcloud của các từ phổ biến nhất"
      ],
      "metadata": {
        "id": "P1iLsjvJE5s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordCloud_generator(data_comment):\n",
        "    wordcloud = WordCloud(width = 800, height = 800,\n",
        "                          background_color ='black',\n",
        "                          min_font_size = 10,\n",
        "                          colormap='Pastel1'\n",
        "                         ).generate(\" \".join(data_comment.values))\n",
        "    # plot the WordCloud image                        \n",
        "    plt.figure(figsize = (10, 10), facecolor = None) \n",
        "    plt.imshow(wordcloud, interpolation='bilinear') \n",
        "    plt.axis(\"off\") \n",
        "    plt.tight_layout(pad = 0) \n",
        "    plt.title(\"Most common words in Reviews\",fontsize=30)\n",
        "    plt.show() \n",
        "    \n",
        "wordCloud_generator(data_comment['HComment'])"
      ],
      "metadata": {
        "id": "1ZONUdIqE6jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xử lý trước văn bản\n",
        "\n",
        "\n",
        "Bây giờ, ta sẽ xử lý trước các comment bằng cách sử dụng một số công cụ NLP như:\n",
        "1. Chuyển thành lower case\n",
        "2. Xoá dấu chấm câu\n",
        "3. Xoá những từ dừng\n",
        "4. Stemming\n",
        "5. Bổ sung"
      ],
      "metadata": {
        "id": "RgBKsTjoFe-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "cOCS1UHyHFj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punc=string.punctuation\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def data_preprocessing(txt):\n",
        "    \n",
        "    #converting to lowercase\n",
        "    txt=txt.lower()\n",
        "    \n",
        "    #Removing Punctuation\n",
        "    txt=\"\".join([x for x in txt if x not in punc])\n",
        "    \n",
        "    #Removing stopwords\n",
        "    txt=\" \".join([word for word in str(txt).split() if word not in stop_words])\n",
        "    \n",
        "    #Stemming\n",
        "    txt = \" \".join([stemmer.stem(word) for word in txt.split()])\n",
        "    \n",
        "    #Lemmatization\n",
        "    txt = \" \".join([lemmatizer.lemmatize(word) for word in txt.split()])\n",
        "\n",
        "    return txt\n",
        "\n",
        "data_comment['text'] = data_comment['HComment'].apply(data_preprocessing)"
      ],
      "metadata": {
        "id": "HCDQ1XpVGGql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_rating = data_comment[[\"HComment\", 'HTravelerRating', 'text']]"
      ],
      "metadata": {
        "id": "0NhEtOk3IkRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xoa cac hang co chua gia tri null\n",
        "data_rating = data_rating[data_rating['HComment'].notna()]\n",
        "data_rating = data_rating[data_rating['HTravelerRating'].notna()]\n",
        "data_rating = data_rating[data_rating['text'].notna()]"
      ],
      "metadata": {
        "id": "s5oi-Az7Bey3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Xem tap du lieu moi\n",
        "data_rating"
      ],
      "metadata": {
        "id": "5sIuGVJTCt5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectơ hóa văn bản đầu vào"
      ],
      "metadata": {
        "id": "p9qDhpggI7NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bây giờ chúng ta sẽ vectơ rating bằng cách sử dụng điểm TF-IDF và chúng ta sẽ sử dụng toarray () để chuyển đổi ma trận thưa thớt kết quả thành ma trận dày đặc.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MaEvEW2DI8Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Tạo một đối tượng của class TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfconverter = TfidfVectorizer(max_features=400, min_df=0.05, max_df=0.9)\n",
        "tfidf = tfidfconverter.fit_transform(data_rating['text']).toarray()"
      ],
      "metadata": {
        "id": "_TML_WYbI72D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chia thành các training sets và test sets"
      ],
      "metadata": {
        "id": "ZMGz36JeJqMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidf,data_rating['HTravelerRating'],test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "NwT4EEZVI628"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lấy mẫu ngược bằng SMOTE\n",
        "\n",
        "Vì biến mục tiêu của ta không cân bằng, ta sẽ sử dụng thuật toán SMOTE để lấy mẫu thêm cho các lớp thiểu số."
      ],
      "metadata": {
        "id": "u4n94w2YJ99D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "print(\"Trước khi lấy mẫu ngược:-\")\n",
        "print(Counter(y_train))\n"
      ],
      "metadata": {
        "id": "LlM8PYy2KHxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Su dung SMOTE de lay mau\n",
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Sau khi lấy mẫu ngược:-\")\n",
        "print(Counter(y_train))"
      ],
      "metadata": {
        "id": "6KyxqThZKhri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "hwqqtNq6EJgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Naive Bayes"
      ],
      "metadata": {
        "id": "mlSzCG8-EQxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training a Naive Bayes classifier \n",
        "#very fast\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB().fit(X_train, y_train) \n",
        "\n",
        "y_pred_NB=mnb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy of Multinominal Naive Balyes:\",accuracy_score(y_test, y_pred_NB))\n",
        "print(classification_report(y_pred_NB,y_test))"
      ],
      "metadata": {
        "id": "f4j0veW4EGIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Support Vector Machines(SVM)"
      ],
      "metadata": {
        "id": "Hn6CjUlwEVNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REVIEW HOTEL COMMENTS VIETNAMESE"
      ],
      "metadata": {
        "id": "kym0rcWjxSK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "5shaLSsKLt6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "yIO8e4Z0L_0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JuqgRIbTL_Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doc file\n",
        "data_comment_viet = pd.read_csv(\"ThuaThienHue_cmt_Viet.csv\")"
      ],
      "metadata": {
        "id": "vpjDipywxbOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_comment_viet.sample(4)"
      ],
      "metadata": {
        "id": "Beb5P2TsxReC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Llorshk_xj_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}